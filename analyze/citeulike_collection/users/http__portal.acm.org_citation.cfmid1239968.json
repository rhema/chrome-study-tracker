{"acm_portal":{"simpl.id":"216830034","location":"http:\/\/dl.acm.org\/citation.cfm?id=1239968&preflayout=flat","pages":"201 - 219","title":"A Bayesian approach for structural learning with hidden Markov models","abstract":"Hidden Markov Models(HMM) have proved to be a successful modeling paradigm for dynamic and spatial processes in many domains, such as speech recognition, genomics, and general sequence alignment. Typically, in these applications, the model structures are predefined by domain experts. Therefore, the HMM learning problem focuses on the learning of the parameter values of the model to fit the given data sequences. However, when one considers other domains, such as, economics and physiology, model structure capturing the system dynamic behavior is not available. In order to successfully apply the HMM methodology in these domains, it is important that a mechanism is available for automatically deriving the model structure from the data. This paper presents a HMM learning procedure that simultaneously learns the model structure and the maximum likelihood parameter values of a HMM from data. The HMM model structures are derived based on the Bayesian model selection methodology. In addition, we introduce a new initialization procedure for HMM parameter value estimation based on the K-means clustering method. Experimental results with artificially generated data show the effectiveness of the approach.","additional_locations":{"location":["http:\/\/portal.acm.org\/citation.cfm?id=1239968&preflayout=flat","http:\/\/dl.acm.org\/citation.cfm?id=1239968&preflayout=flat","http:\/\/portal.acm.org\/citation.cfm?id=1239968"]},"clippings":[{"text_clipping":{"context":"A Bayesian approach for structural learning with hidden Markov models","text":"A Bayesian approach for structural learning with hidden Markov models","acm_portal":{"simpl.ref":"216830034"}}}],"authors":{"author":[{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81100479323","name":"Cen Li","affiliations":{"acm_portal_institution_profile":[{"mm_name":"affiliations","location":"http:\/\/dl.acm.org\/inst_page.cfm?id=1030272&CFID=196240317&CFTOKEN=18819485","title":"Department of Computer Science, Middle Tennessee State University, Box 48, Murfreesboro, TN 37132, Tel.: +1 615 904 8168; Fax: +1 615 898 5567; E-mail: cli@mtsu.edu"}]}},{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81100075566","name":"Gautam Biswas","affiliations":{"acm_portal_institution_profile":[{"mm_name":"affiliations","location":"http:\/\/dl.acm.org\/inst_page.cfm?id=1031836&CFID=196240317&CFTOKEN=18819485","title":"Department of Electrical and Computer Engineering, Vanderbilt University, Box 1679 Station B, Nashville, TN 37235, USA. Tel.: +1 615 343 6204; Fax: +1 615 343 5459; E-mail: biswas@vuse.vanderbilt. ..."}]}}]},"references":[{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=1214993&preflayout=flat","title":"Speech and Language Processing (2nd Edition)","authors":{"author":[{"mm_name":"authors","name":"Daniel Jurafsky"},{"mm_name":"authors","name":"James H. Martin"}]},"source":{"mm_name":"source","year":"2006","title":"Prentice-Hall, Inc., Upper Saddle River, NJ, 2006"}}},{"acm_portal":{"mm_name":"references","title":"[2] S. Rogic, A. K. Mackworth and F. B. F. Ouellette, Evaluation of gene-finding programs on mammalian sequences, Genomic Research 11 (2001), 817-832."}},{"acm_portal":{"mm_name":"references","title":"[3] L. R. Rabiner, Atutorial on hidden markov models and selected applications in speech recognition, Proceedings of the IEEE 77(2) (Feb. 1989), 257-285."}},{"acm_portal":{"mm_name":"references","title":"[4] W. J. Stewart, Introduction to the Numerical Solution of Markov Chains, Princeton University Press, 1994."}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=657799&preflayout=flat","title":"A Bayesian Approach to Temporal Data Clustering using Hidden Markov Models","authors":{"author":[{"mm_name":"authors","name":"Cen Li"},{"mm_name":"authors","name":"Gautam Biswas"}]},"source":{"mm_name":"source","year":"2000","title":"Proceedings of the Seventeenth International Conference on Machine Learning, p.543-550, June 29-July 02, 2000"}}},{"acm_portal":{"mm_name":"references","title":"P. F. Brown","authors":{"author":[{"mm_name":"authors","name":"[6] L. R. Bahl"}]},"source":{"mm_name":"source","year":"1986","title":"P. V. De Souza and R. L. Mercer, Maximum mutual information estimation of hidden markov model parameters, in: Proceedings of the IEEE-IECEJ-AS International Conference on Acoustics, Speech, and Signal Processing , (Vol. 1), 1986, pp. 49-52."}}},{"acm_portal":{"mm_name":"references","title":"[7] Y. Singer and M. Warmuth, Training algorithms for hidden markov models using entropy based distance functions, Advances in Neural Information Processing Systems 9(1996), 641-647."}},{"acm_portal":{"mm_name":"references","title":"[8] S. Kwong, Q. H. He and K. F. Man, Training approaches for hidden markov models, Electronics Letters 32(17) (1996), 1554-1555."}},{"acm_portal":{"mm_name":"references","title":"[9] L. E. Baum, T. Petrie, G. Soules and N. Weiss, A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains, The Annuals of Mathematical Statistics 4(1) (1970), 164-171."}},{"acm_portal":{"mm_name":"references","title":"[10] A. P. Dempster, N. M. Laird and D. B. Rubin, Maximum likelihood from incomplete data via the em algorithm, Journal of Royal Statistical Society Series B(methodological) 39 (1977), 1-38."}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=274165&preflayout=flat","title":"Factorial Hidden Markov Models","authors":{"author":[{"mm_name":"authors","name":"Zoubin Ghahramani"},{"mm_name":"authors","name":"Michael I. Jordan"}]},"source":{"mm_name":"source","year":"4087","title":"Machine Learning, v.29 n.2-3, p.245-273, Nov.\/Dec. 1997 ￂﾠ[doi>10.1023\/A:1007425814087]"}}},{"acm_portal":{"mm_name":"references","title":"[12] A. Stolcke and S. M. Omohundro, Best-first model merging for hidden markov model induction, Tech. Rep. TR-94-003, International Computer Science Institute, 1947 Center St., Suite 600, Berkeley, CA 94704-1198, Jan. 1994."}},{"acm_portal":{"mm_name":"references","title":"[13] F. Casacuberta, E. Vidal and B. Mas, Learning the structure of hmm's through grammatical inference techniques, in: Proceedings of the International Conference on Acoustic, Speech, and Signal Processing, 1990, pp. 717-720."}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=327273&preflayout=flat","title":"Structure learning in  conditional probability models via an entropic prior and parameter extinction","authors":{"author":[{"mm_name":"authors","name":"Matthew Brand"}]},"source":{"mm_name":"source","year":"6395","title":"Neural Computation, v.11 n.5, p.1155-1182, July 1, 1999 ￂﾠ[doi>10.1162\/089976699300016395]"}}},{"acm_portal":{"mm_name":"references","title":"[15] J. Takami and S. Sagayama, A successive state splitting algorithm for efficient allophone modeling, in: Proceedings of the International Conference on Acoustics, Speech, and Signal Processing 1, 1992, pp. 573-576."}},{"acm_portal":{"mm_name":"references","title":"[16] M. Ostendorf and H. Singer, Hmmtopology design using maximum likelihood successive state splitting, Computer Speech and Language 11 (1997), 17-41."}},{"acm_portal":{"mm_name":"references","title":"[17] Z. Ghahramani and M. J. Beal, Graphical models and variational methods, in: Advanced Mean Field Methods - Theory and Practice, D. Saad and M. Opper, eds, MIT press, 1999."}},{"acm_portal":{"mm_name":"references","title":"[18] Z. Ghahramani and M. J. Beal, Variational inference for bayesian mixtures of factor analysers, in: Advances in Neural Information Processing Systems, (Vol. 12), S. A. Solla, T. K. Leen and K. R. Muller, eds, MIT press, Cambridge, MA, 1999."}},{"acm_portal":{"mm_name":"references","title":"A variational bayesian framework for graphical models, in: Advances in Neural Information Processing Systems","authors":{"author":[{"mm_name":"authors","name":"[19] H. Attias"}]},"source":{"mm_name":"source","year":"2000","title":"T. et al. Leen, ed., MIT press, Cambridge, MA, 2000."}}},{"acm_portal":{"mm_name":"references","title":"[20] S. Chib, Marginal likelihood from the gibbs sampling, Journal of the American Statistical Association (Dec. 1995), 1313- 1321."}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=145259&preflayout=flat","title":"A Bayesian Method for the Induction of Probabilistic Networks from Data","authors":{"author":[{"mm_name":"authors","name":"Gregory F. Cooper"},{"mm_name":"authors","name":"Edward Herskovits"}]},"source":{"mm_name":"source","year":"1552","title":"Machine Learning, v.9 n.4, p.309-347, Oct. 1992 ￂﾠ[doi>10.1023\/A:1022649401552]"}}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=218921&preflayout=flat","title":"Learning Bayesian Networks: The Combination of Knowledge and Statistical Data","authors":{"author":[{"mm_name":"authors","name":"David Heckerman"},{"mm_name":"authors","name":"Dan Geiger"},{"mm_name":"authors","name":"David M. Chickering"}]},"source":{"mm_name":"source","year":"503","title":"Machine Learning, v.20 n.3, p.197-243, Sept. 1995 ￂﾠ[doi>10.1023\/A:1022623210503]"}}},{"acm_portal":{"mm_name":"references","title":"[23] R. E. Kass and A. E. Raftery, Bayes factor, Journal of the American Statistical Association (June 1995), 773-795."}},{"acm_portal":{"mm_name":"references","title":"[24] G. Casella and E. I. George, Explaining the gibbs sampler, The American Statistician 46(3) (Aug. 1992), 167-174."}},{"acm_portal":{"mm_name":"references","title":"[25] G. Schwarz, Estimating the dimension of a model, Annuals of Statistics 6(1978), 461-464."}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=257954&preflayout=flat","title":"Bayesian classification (AutoClass): theory and results","authors":{"author":[{"mm_name":"authors","name":"Peter Cheeseman"},{"mm_name":"authors","name":"John Stutz"}]},"source":{"mm_name":"source","year":"1996","title":"Advances in knowledge discovery and data mining, American Association for Artificial Intelligence, Menlo Park, CA, 1996"}}},{"acm_portal":{"mm_name":"references","title":"[27] J. Rissanen, A universal prior for integers and estimation by minimum description length, Annual of Statistics 11 (1983), 416-431."}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=925979&preflayout=flat","title":"Supervised classification with temporal data","authors":{"author":[{"mm_name":"authors","name":"Stefanos Manganaris"},{"mm_name":"authors","name":"Douglas H. Fisher"}]},"source":{"mm_name":"source","year":"1997","title":"Vanderbilt University, Nashville, TN, 1997"}}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=274163&preflayout=flat","title":"Efficient Approximations for the MarginalLikelihood of Bayesian Networks with Hidden Variables","authors":{"author":[{"mm_name":"authors","name":"David Maxwell Chickering"},{"mm_name":"authors","name":"David Heckerman"}]},"source":{"mm_name":"source","year":"9108","title":"Machine Learning, v.29 n.2-3, p.181-212, Nov.\/Dec. 1997 ￂﾠ[doi>10.1023\/A:1007469629108]"}}},{"acm_portal":{"mm_name":"references","title":"J. B. Carlin and D. B. Rubin","authors":{"author":[{"mm_name":"authors","name":"[30] A. Gelman"}]},"source":{"mm_name":"source","year":"1995","title":"Bayesian Data Analysis , Chapman & Hall\/CRC, Boca Raton, 1995."}}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=657974&preflayout=flat","title":"Model Selection Criteria for Learning Belief Nets: An Empirical Comparison","authors":{"author":[{"mm_name":"authors","name":"Tim Van Allen"},{"mm_name":"authors","name":"Russell Greiner"}]},"source":{"mm_name":"source","year":"2000","title":"Proceedings of the Seventeenth International Conference on Machine Learning, p.1047-1054, June 29-July 02, 2000"}}},{"acm_portal":{"mm_name":"references","title":"[32] A. N. Jain and B. Chandrasekaran, Dimensionality and sample size considerations in pattern recognition practice, in: Handbook of statistics, P. R. Krishnaiah and L. N. Kanal, eds, North-Holland Publishing Company, Amsterdam, 1982, pp. 835- 855."}},{"acm_portal":{"mm_name":"references","location":"http:\/\/dl.acm.org\/citation.cfm?id=42779&preflayout=flat","title":"Algorithms for clustering data","authors":{"author":[{"mm_name":"authors","name":"Anil K. Jain"},{"mm_name":"authors","name":"Richard C. Dubes"}]},"source":{"mm_name":"source","year":"1988","title":"Prentice-Hall, Inc., Upper Saddle River, NJ, 1988"}}}],"citations":[{"acm_portal":{"mm_name":"citations","location":"http:\/\/dl.acm.org\/citation.cfm?id=1426061&preflayout=flat","title":"Using Hidden Markov Models to Characterize Student Behaviors in Learning-by-Teaching Environments","authors":{"author":[{"mm_name":"authors","name":"Hogyeong Jeong"},{"mm_name":"authors","name":"Amit Gupta"},{"mm_name":"authors","name":"Rod Roscoe"},{"mm_name":"authors","name":"John Wagster"},{"mm_name":"authors","name":"Gautam Biswas"},{"mm_name":"authors","name":"Daniel Schwartz"}]},"source":{"mm_name":"source","year":"2008","title":"Proceedings of the 9th international conference on Intelligent Tutoring Systems, June 23-27, 2008, Montreal, Canada"}}}],"rich_media":{"mm_name":"rich_media","title":"PDF full text"},"source":{"mm_name":"source","title":"Scientific Programming - Hidden Markov Models            \n\t\t           tableￂﾠofￂﾠcontents\n\t\t\t    \n              archive","articles":{"acm_portal":[{"mm_name":"articles","location":"http:\/\/dl.acm.org\/citation.cfm?id=1239970&preflayout=flat","title":"Introduction","authors":{"author":[{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81328490693","name":"Staff"}]}},{"mm_name":"articles","location":"http:\/\/dl.acm.org\/citation.cfm?id=1239969&preflayout=flat","title":"Fitting hidden Markov models to psychological data","authors":{"author":[{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81328490792","name":"Ingmar Visser"},{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81328490792","name":"Maartje E. J. Raijmakers"},{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81328490792","name":"Peter C. M. Molenaar"}]}},{"mm_name":"articles","location":"http:\/\/dl.acm.org\/citation.cfm?id=1239968&preflayout=flat","title":"A Bayesian approach for structural learning with hidden Markov models","authors":{"author":[{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81100479323","name":"Cen Li"},{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81100479323","name":"Gautam Biswas"}]}},{"mm_name":"articles","location":"http:\/\/dl.acm.org\/citation.cfm?id=1239967&preflayout=flat","title":"HMM-based techniques for speech segments extraction","authors":{"author":[{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81100490080","name":"Waleed H. Abdulla"}]}},{"mm_name":"articles","location":"http:\/\/dl.acm.org\/citation.cfm?id=1239966&preflayout=flat","title":"On determining the order of Markov dependence of an observed process governed by a hidden Markov model","authors":{"author":[{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81100617622","name":"R. J. Boys"},{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81100617622","name":"D. A. Henderson"}]}},{"mm_name":"articles","location":"http:\/\/dl.acm.org\/citation.cfm?id=1239965&preflayout=flat","title":"OpenMP programming for a global inverse model","authors":{"author":[{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81328490950","name":"Ping Wang"},{"mm_name":"authors","location":"http:\/\/dl.acm.org\/author_page.cfm?id=81328490950","name":"Xiaoping Wu"}]}}]}}}}